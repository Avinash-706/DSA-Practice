=============================
TREE
 =============================

 INTRODUCTION TO TREE DATA STRUCTURE  
  A tree is a widely used NON-LINEAR data structure that represents data in a HIERARCHICAL fashion  
  Unlike linear data structures (arrays, linked lists, stacks, queues) which store data sequentially,  
  a tree is comprised of NODES connected by EDGES, illustrating PARENT-CHILD relationships  
  This structure is RECURSIVE in nature, as each child of a node can be the root of its own subtree  
  Trees are used to model scenarios involving hierarchy, such as:  
  -> Organization structures  
  -> File systems  
 

 -----------------------------
 TERMINOLOGIES
  -----------------------------
  NODE            -> An individual element in a tree that stores data and may have links to other nodes  
  ROOT NODE       -> The topmost node in a tree hierarchy (no parent)  
  PARENT NODE     -> The immediate predecessor of a node  
  CHILD NODE      -> The immediate successor of a node  
  LEAF NODE       -> A node with no children (degree 0)  
  INTERNAL NODE   -> A node having at least one child (non-leaf)  
  SUBTREE         -> A portion of the tree that forms a complete tree itself with a child node as root  
  DESCENDANTS     -> All the nodes in the subtree of a node  
  ANCESTORS       -> The node's parent, grandparent, and so on up to the root  
  DEGREE OF NODE  -> Number of children of the node (leaf node has degree 0)  
  
  -----------------------------
  EXAMPLE TREE FOR TERMINOLOGIES
  -----------------------------
            A (Root)
           / \
          B   C
         / \   \
        D   E   F
           /
          G
  
   EXPLANATION:
   -> ROOT NODE      : A  
   -> PARENT NODE    : A (parent of B, C), B (parent of D, E), C (parent of F), E (parent of G)  
   -> CHILD NODE     : B, C (children of A), D, E (children of B), F (child of C), G (child of E)  
   -> LEAF NODE      : D, G, F  
   -> INTERNAL NODE  : A, B, C, E  
   -> SUBTREE        : Tree starting at node B (includes D, E, G)  
   -> DESCENDANTS    : Descendants of B → D, E, G  
   -> ANCESTORS      : Ancestors of G → E, B, A  
   -> DEGREE         : Degree of A = 2, Degree of E = 1, Degree of D = 0  
  


 -----------------------------
 APPLICATIONS OF TREE DATA STRUCTURE
  -----------------------------
  -> Representing HIERARCHICAL DATA (e.g., organization structure)  
  -> Folder structure in operating systems  
  -> Parsing XML/HTML content (DOM structure)  
  -> Binary Search Tree (efficient searching, insertion, deletion)  
  -> Binary Heap (priority queue implementation)  
  -> B & B+ Trees (database indexing)  
  -> Network routing (spanning tree, shortest path tree)  
  -> Compilers (parse trees / abstract syntax trees)  
  -> Trie (dictionary & prefix search)  
  -> Suffix Tree (pattern matching)  
  -> Binary Indexed Tree & Segment Tree (range queries)  
 


 =============================
 BINARY TREE
  =============================
  DEFINITION:
   A binary tree is a specific type of tree where EVERY NODE has AT MOST 2 children (0 to max 2 children)  
   
  -----------------------------
  EXAMPLE OF BINARY TREE
   -----------------------------
          1
         / \
        2   3
       / \   \
      4   5   6
  
   In this example:
   -> Node 1 has two children (2, 3)  
   -> Node 2 has two children (4, 5)  
   -> Node 3 has one child (6)  
   -> Nodes 4, 5, 6 have no children (leaf nodes)  
  
  -----------------------------
  REPRESENTATION
   -----------------------------
   1) LINKED REPRESENTATION  
      -> Each node contains:
         - Data field (key)  
         - Pointer to left child  
         - Pointer to right child  
      -> If a child does not exist, its pointer is NULL  
      -> Leaf nodes have both pointers NULL  
  
   2) ARRAY REPRESENTATION  
      -> Suitable for complete binary trees  
      -> Root stored at index 0  
      -> For node at index i:
         - Left child index  = 2*i + 1  
         - Right child index = 2*i + 2  
  
  -----------------------------
  IMPLEMENTATION LOGIC
   -----------------------------
   -> Create a Node structure/class with data, left pointer, right pointer  
   -> Initialize left & right pointers as NULL  
   -> Start with creating the root node  
   -> Dynamically link new nodes as left or right children of appropriate parents  
 


 =============================
 TREE TRAVERSAL
  =============================
 
  -----------------------------
  INTRODUCTION TO TREE TRAVERSAL
   -----------------------------
   -> Tree Traversal is the process of visiting (checking, updating, or printing) each node in a tree data structure, EXACTLY ONCE.
   -> This systematic way of visiting nodes is fundamental for many tree-based operations.
   
   WHY IS TRAVERSAL NEEDED?
    -> SEARCHING: To find if an element exists in a tree.
    -> COUNTING: To find the total number of nodes (the size of the tree).
    -> INSERTING / DELETING: Locating the correct position for insertion or deletion.
    -> MANY OTHER ALGORITHMS that build upon visiting all nodes.
   
 
  -----------------------------
  TYPES OF TRAVERSAL: DFS vs BFS
   -----------------------------
   -> Traversal algorithms can be broadly classified into two main categories:
      ✅ BREADTH-FIRST SEARCH (BFS)
      ✅ DEPTH-FIRST SEARCH (DFS)
   
   COMPARISON TABLE:
    ================================================================================================
    |      FEATURE      |        BREADTH-FIRST SEARCH (BFS)        |         DEPTH-FIRST SEARCH (DFS)        |
    |-------------------|------------------------------------------|-----------------------------------------|
    | APPROACH          | Explores LEVEL by LEVEL (like reading a  | Explores as far as possible down one    |
    |                   | book, line by line, from top to bottom)  | branch before backtracking              |
    |-------------------|------------------------------------------|-----------------------------------------|
    | DATA STRUCTURE    | Uses a QUEUE to keep track of nodes to   | Uses a STACK (often implicitly via      |
    |                   | visit next                               | RECURSION)                              |
    |-------------------|------------------------------------------|-----------------------------------------|
    | TRAVERSAL NAMES   | Level Order Traversal                    | Preorder, Inorder, Postorder            |
    |-------------------|------------------------------------------|-----------------------------------------|
    | MEMORY USAGE      | Can be high if the tree is very WIDE     | Can be high if the tree is very DEEP    |
    |-------------------|------------------------------------------|-----------------------------------------|
    | PATH FINDING      | ✅ Finds the SHORTEST PATH in terms of   | ❌ Not guaranteed to find the shortest |
    |                   | edges from the root in an unweighted tree| path                                    |
    ==========================================================================================================
   
   
  -----------------------------
  DEPTH FIRST SEARCH (DFS) TRAVERSALS
   -----------------------------
   -> DFS explores one side of the tree completely before moving to the other side.
   -> It is most easily and intuitively implemented using RECURSION.
   
   CORE RECURSIVE TASKS:
    For any given node (considered as a root of its own subtree), we have three tasks:
    1. Process the ROOT node (e.g., print its value)
    2. Traverse the LEFT subtree (a recursive call)
    3. Traverse the RIGHT subtree (a recursive call)
   
   -> The order in which these three tasks are performed gives us different DFS traversals.
   -> While there are 3! (or 6) possible permutations, the 3 most popular ones always traverse the LEFT subtree before the RIGHT subtree.
   
    1. INORDER   (Left, Root, Right)
    2. PREORDER  (Root, Left, Right)
    3. POSTORDER (Left, Right, Root)
   
 
 
  -----------------------------
  EXAMPLE TREE FOR TRAVERSALS
   -----------------------------
   -> The following tree will be used to explain Inorder, Preorder, and Postorder traversals.
   
             10
            /  \
           20   30
          /  \    \
         40  50    60
            /  \
           70  80
 
  -----------------------------
  1. INORDER TRAVERSAL (LEFT - ROOT - RIGHT)
   -----------------------------
   EXPLANATION:
    -> For any node, we first completely traverse its LEFT child's subtree, then visit the ROOT node itself, and finally, completely traverse its RIGHT child's subtree.
 
   RECURSION CALL STACK TRACE:
    inorder(10)
    -> inorder(20)
       -> inorder(40) -> prints 40
       -> print(20)
       -> inorder(50)
          -> inorder(70) -> prints 70
          -> print(50)
          -> inorder(80) -> prints 80
    -> print(10)
    -> inorder(30)
       -> inorder(NULL)
       -> print(30)
       -> inorder(60) -> prints 60
 
    FINAL OUTPUT: 40 20 70 50 80 10 30 60
   
   PSEUDOCODE:
    function inorder(node):
      if node is NULL: return
      inorder(node.left)
      print(node.data)
      inorder(node.right)
   
   TIME COMPLEXITY:
    -> Θ(n), where 'n' is the number of nodes.
   
   AUXILIARY SPACE COMPLEXITY:
    -> Θ(h), where 'h' is the height of the tree.
   
 
  -----------------------------
  2. PREORDER TRAVERSAL (ROOT - LEFT - RIGHT)
   -----------------------------
   EXPLANATION:
    -> For any node, we first visit the ROOT node itself, then completely traverse its LEFT subtree, and finally, completely traverse its RIGHT subtree.
 
   RECURSION CALL STACK TRACE:
    preorder(10)
    -> print(10)
    -> preorder(20)
       -> print(20)
       -> preorder(40) -> prints 40
       -> preorder(50)
          -> print(50)
          -> preorder(70) -> prints 70
          -> preorder(80) -> prints 80
    -> preorder(30)
       -> print(30)
       -> preorder(NULL)
       -> preorder(60) -> prints 60
 
    FINAL OUTPUT: 10 20 40 50 70 80 30 60
   
   PSEUDOCODE:
    function preorder(node):
      if node is NULL: return
      print(node.data)
      preorder(node.left)
      preorder(node.right)
   
   TIME COMPLEXITY:
    -> Θ(n)
   
   AUXILIARY SPACE COMPLEXITY:
    -> Θ(h)
   
 
  -----------------------------
  3. POSTORDER TRAVERSAL (LEFT - RIGHT - ROOT)
   -----------------------------
   EXPLANATION:
    -> For any node, we first completely traverse its LEFT subtree, then completely traverse its RIGHT subtree, and finally, visit the ROOT node itself.
 
   RECURSION CALL STACK TRACE:
    postorder(10)
    -> postorder(20)
       -> postorder(40) -> prints 40
       -> postorder(50)
          -> postorder(70) -> prints 70
          -> postorder(80) -> prints 80
          -> print(50)
       -> print(20)
    -> postorder(30)
       -> postorder(60) -> prints 60
       -> print(30)
    -> print(10)
 
    FINAL OUTPUT: 40 70 80 50 20 60 30 10
   
   PSEUDOCODE:
    function postorder(node):
      if node is NULL: return
      postorder(node.left)
      postorder(node.right)
      print(node.data)
   
   TIME COMPLEXITY:
    -> Θ(n)
   
   AUXILIARY SPACE COMPLEXITY:
    -> Θ(h)



 =============================
 HEIGHT OF BINARY TREE
  =============================
 
  -----------------------------
  INTRODUCTION
   -----------------------------
   -> The height of a binary tree is the number of nodes on the longest path from the root node down to the furthest leaf node.
   
   DEFINITIONS:
    -> The height of a tree with a single node is 1.
    -> The height of an empty tree (or a NULL node) is 0.
   
 
  -----------------------------
  EXAMPLE TREE
   -----------------------------
   -> The following tree will be used for the explanation, which has a height of 4.
   
             10
            /  \
           20   30
          /  \    \
         40  50    60
            /  \
           70  80
 
  -----------------------------
  RECURSIVE LOGIC    --    DFS LOGIC : POST-ORDER TRAVERSAL TECHNIQUE
   -----------------------------
   -> The height of a tree can be found by recursively calculating the height of its subtrees.
   -> This approach follows a post-order traversal pattern: first process the left and right children, then process the parent.
   
   CORE IDEA:
    For any given node, its height is:
    ✅ 1 + max(height of its left subtree, height of its right subtree)
    
   BASE CASE:
    -> If a node is NULL, its height is 0. This stops the recursion.
   
 
  -----------------------------
  RECURSIVE CALL STACK TRACE
   -----------------------------
   -> This trace shows how the height is calculated from the bottom up.
   
   height(10)
   |
   |-- L: height(20)
   |   |
   |   |-- L: height(40)
   |   |   |-- L: height(NULL) -> returns 0
   |   |   |-- R: height(NULL) -> returns 0
   |   |   `-- returns max(0, 0) + 1 = 1
   |   |
   |   |-- R: height(50)
   |   |   |-- L: height(70)
   |   |   |   |-- L: height(NULL) -> returns 0
   |   |   |   |-- R: height(NULL) -> returns 0
   |   |   |   `-- returns max(0, 0) + 1 = 1
   |   |   |
   |   |   |-- R: height(80)
   |   |   |   |-- L: height(NULL) -> returns 0
   |   |   |   |-- R: height(NULL) -> returns 0
   |   |   |   `-- returns max(0, 0) + 1 = 1
   |   |   |
   |   |   `-- returns max(1, 1) + 1 = 2
   |   |
   |   `-- returns max(height(40), height(50)) + 1 => max(1, 2) + 1 = 3
   |
   |-- R: height(30)
   |   |
   |   |-- L: height(NULL) -> returns 0
   |   |
   |   |-- R: height(60)
   |   |   |-- L: height(NULL) -> returns 0
   |   |   |-- R: height(NULL) -> returns 0
   |   |   `-- returns max(0, 0) + 1 = 1
   |   |
   |   `-- returns max(height(NULL), height(60)) + 1 => max(0, 1) + 1 = 2
   |
   `-- returns max(height(20), height(30)) + 1 => max(3, 2) + 1 = 4
   
 
  -----------------------------
  PSEUDOCODE      --    DFS LOGIC : POST-ORDER TRAVERSAL TECHNIQUE
   -----------------------------
   function getHeight(node):
     if node is NULL: return 0
     leftHeight = getHeight(node.left)
     rightHeight = getHeight(node.right)
     return max(leftHeight, rightHeight) + 1
   
  -----------------------------
  COMPLEXITY
   -----------------------------
   TIME COMPLEXITY:
    -> Θ(n), as every node in the tree must be visited exactly once.
   
   AUXILIARY SPACE COMPLEXITY:
    -> Θ(h), where 'h' is the height of the tree. This space is used by the recursion call stack.



 ============================================================
 HOW INORDER + PREORDER HELPS TO CREATE BINARY TREE
  ============================================================
 
  PREORDER TRAVERSAL  : Root → Left → Right
  INORDER TRAVERSAL   : Left → Root → Right
  
  ------------------------------------------------------------
  MAIN WORKING IDEA
   ------------------------------------------------------------
   -> Preorder always gives the ROOT as the first element.
   -> Inorder tells us the boundary between LEFT and RIGHT subtrees.
   -> By repeatedly picking elements from Preorder and locating them
      in Inorder, we can recursively split the tree.
  
  ------------------------------------------------------------
  STEP-BY-STEP WORKING
   ------------------------------------------------------------
   1. Start with Preorder[0] → this is the ROOT.
   2. Find this root element in the Inorder array.
   3. Elements LEFT of root in Inorder → Left Subtree.
   4. Elements RIGHT of root in Inorder → Right Subtree.
   5. Recur for LEFT and RIGHT subtrees using the same process.
  
  ------------------------------------------------------------
  EXAMPLE
   ------------------------------------------------------------
   Preorder = [1, 2, 4, 5, 3, 6]
   Inorder  = [4, 2, 5, 1, 6, 3]
   
   Step 1: Pre[0] = 1 → ROOT = 1
           Inorder position of 1 splits array:
           Left Subtree Inorder  = [4, 2, 5]
           Right Subtree Inorder = [6, 3]
   
   Step 2: Next Pre element = 2 → ROOT of LEFT subtree
           Inorder position of 2 splits left part:
           Left Subtree Inorder  = [4]
           Right Subtree Inorder = [5]
   
   Step 3: Next Pre element = 4 → ROOT of LEFT-LEFT
           No children (single element)
   
   Step 4: Next Pre element = 5 → ROOT of LEFT-RIGHT
           No children
   
   Step 5: Next Pre element = 3 → ROOT of RIGHT subtree
           Inorder position splits into:
           Left = [6], Right = []
   
   Step 6: Next Pre element = 6 → ROOT of RIGHT-LEFT
   
   Final Tree Constructed:
               1
             /   \
            2     3
           / \   /
          4   5 6
  
  ------------------------------------------------------------
  WHY THIS WORKS
   ------------------------------------------------------------
   -> Preorder guarantees the ROOT order.
   -> Inorder guarantees correct LEFT and RIGHT separation.
   -> Combining both ensures the tree can be built uniquely.


  ============================================================
  TRAVERSAL COMBINATION         CAN BUILD UNIQUE TREE?
   ============================================================
   Preorder  + Inorder            YES
   Postorder + Inorder            YES
   Inorder +  Preorder            YES (same as above)
   Inorder + Postorder            YES (same as above)
   
   Preorder + Postorder           NO (multiple trees possible)
                                  → Exception: YES if tree is FULL
   
   Preorder only                  NO
   Postorder only                 NO
   Inorder only                   NO


 =============================
 DIAMETER OF A BINARY TREE
  =============================
 
  -----------------------------
  INTRODUCTION
   -----------------------------
   -> The diameter (or width) of a binary tree is the length of the LONGEST PATH between any two nodes in the tree.
   -> The length of a path is measured by the number of edges between the nodes.
   
   IMPORTANT NOTE:
    -> This longest path may or may not pass through the root of the tree.
   
 
  -----------------------------
  EXAMPLE TREE
   -----------------------------
   -> The tree below has a diameter of 6.
   -> The longest path is between node 70 and node 60.
   -> PATH: 70 <-> 50 <-> 20 <-> 10 <-> 30 <-> 60
   
             10
            /  \
           20   30
          /       \
         50        60
        /
       70
 
  -----------------------------
  RECURSIVE LOGIC
   -----------------------------
   -> To find the diameter, we must consider every node as a potential "root" or "turning point" of the longest path.
   
   For any given node, the longest path could be one of three possibilities:
    1. The diameter lies entirely within the node's LEFT subtree.
    2. The diameter lies entirely within the node's RIGHT subtree.
    3. The diameter PASSES THROUGH the current node.
       - The length of this path would be: (height of left subtree) + (height of right subtree).
   
   -> The overall diameter of the tree is the MAXIMUM value found among these three possibilities, calculated for every node.
   
 
  -----------------------------
  OPTIMIZED RECURSIVE APPROACH (O(n))
   -----------------------------
   -> A naive approach would be to calculate the height at every node, leading to an O(n^2) complexity.
   -> A much better way is to calculate both the height and the diameter in a single post-order traversal.
   
   THE STRATEGY:
    -> We create a recursive function that returns the HEIGHT of the subtree it's given.
    -> As this function calculates the height from the bottom up, it also calculates the potential diameter that passes through the current node (`left_height + right_height`).
    -> It compares this `current_diameter` with a global `max_diameter` and updates it if the current one is larger.
    -> This way, by the time the traversal is complete, we have both calculated the tree's height and found the maximum diameter.
   
 
  -----------------------------
  PSEUDOCODE (OPTIMIZED APPROACH)
   -----------------------------
    // `diameter` is a global or reference variable
    function heightAndUpdateDiameter(node):
      if node is NULL: return 0
      lh = heightAndUpdateDiameter(node.left)
      rh = heightAndUpdateDiameter(node.right)
      diameter = max(diameter, lh + rh)
      return 1 + max(lh, rh)
   
  -----------------------------
  COMPLEXITY
   -----------------------------
   TIME COMPLEXITY:
    -> Θ(n), as every node is visited exactly once in the post-order traversal.
   
   AUXILIARY SPACE COMPLEXITY:
    -> Θ(h), where 'h' is the height of the tree, for the recursion call stack.