OVERVIEW ON STRINGS

A STRING is a sequence of characters and serves as an essential data structure in programming. Unlike
character arrays, strings come with specialized operations and optimized storage, making them more efficient for text processing


CHARACTER SETS AND ENCODING

 ASCII (American Standard Code for Information Interchange)
  Uses 8-bit encoding (standard: 128 characters, extended: 256 characters)
  Covers English alphabets, digits, punctuation marks, and control characters
 
 UTF-16 (Unicode Transformation Format - 16 bit)
  Stores a larger set of characters to support multiple languages
  First 128 characters are identical to ASCII, ensuring backward compatibility
  Used in Java as the default encoding for characters


STRING REPRESENTATION IN C++ AND JAVA

 C++ Strings
  Uses 8-bit char type for storage
  Standard strings are implemented via std::string
  wchar_t is available for Unicode storage

 Java Strings
  Uses 16-bit char type with UTF-16 encoding
  Stored as immutable objects in String class
  Allows easy conversion between characters and ASCII/Unicode values


CHARACTER VALUE MAPPING

 -> ASCII values of characters:
  'a' -> 97, 'b' -> 98, ..., 'z' -> 122
  'A' -> 65, 'B' -> 66, ..., 'Z' -> 90
   Numeric and special symbols also have specific values

 -> Unicode values:
  First 128 values match ASCII
  Extended characters provide support for multiple languages


STRING OPERATIONS AND ALGORITHMS

 COMMON STRING OPERATIONS

  -> Concatenation
  -> Substring extraction
  -> Length determination
  -> Character access
  -> Comparison

 IMPORTANT STRING ALGORITHMS

  -> Palindrome Check
  -> Subsequence Checking
  -> Anagram Detection
  -> Pattern Searching (Naive, Rabin-Karp, KMP)
  -> Finding Leftmost Repeating & Non-Repeating Characters
  -> Reversing Words in a String
  -> Lexicographic Rank Calculation
  -> Finding the Longest Substring with Distinct Characters


KEY TAKEAWAYS

 -> Strings are more than just character arrays; they have optimized memory and built-in functionalities
 -> ASCII and Unicode provide different ways to represent characters, with UTF-16 supporting a wider range of languages
 -> Java and C++ handle strings differently but maintain fundamental similarities in character value mapping
 -> Understanding string algorithms is crucial for solving competitive programming and real-world problems efficiently


PATTERN SEARCHING IN STRINGS

 The PATTERN SEARCHING PROBLEM involves finding all occurrences of a smaller string (pattern)
 within a larger string (text). If the pattern is not found, the output is "NOT PRESENT"


 EXAMPLE:
  TEXT: geeksforgeeks
  PATTERN: EKS
  OCCURRENCES: Index 2 and 10


 REAL-WORLD USE CASES:
 Searching text in files (e.g., MS Word, programming files)
 Google Search
 DNA Matching
 Regular Expression Matching


 COMMON PATTERN SEARCHING ALGORITHMS
 +-------------------------------------------+-------------------+
 | ALGORITHM                                 | TIME COMPLEXITY   |
 +-------------------------------------------+-------------------+
 | Naive Pattern Searching                   | O((N - M + 1) * M) |
 | Naive (Distinct Characters)               | O(N)              |
 | Rabin-Karp Algorithm                      | O((N - M + 1) * M) |
 | KMP Algorithm                             | O(N)              |
 | Boyer-Moore Algorithm                     | O(N) (Best Case)  |
 | Z Algorithm                               | O(N)              |
 | Suffix Tree (Preprocessing Text)          | O(M) (Search Time)|
 +-------------------------------------------+-------------------+


 OVERVIEW OF KEY ALGORITHMS
  -> NAIVE PATTERN SEARCHING
   Compares the pattern with every substring window of the text
   Time Complexity: O((N - M + 1) * M)
  
  -> NAIVE (WHEN PATTERN CHARACTERS ARE DISTINCT)
   If all characters in the pattern are distinct, the naive approach can be optimized to O(N) time

  -> RABIN-KARP ALGORITHM
   Uses rolling hash to optimize matching
   If the hash matches, only then it checks individual characters
   Best Case: Faster than naive, Worst Case: Similar to naive

  -> KMP ALGORITHM (Knuth-Morris-Pratt)
   Preprocesses the pattern to handle redundancies efficiently
   Uses an LPS (Longest Proper Prefix which is also Suffix) array to avoid redundant comparisons
   Time Complexity: O(N)

  -> BOYER-MOORE ALGORITHM
   Searches the pattern from right to left instead of left to right
   Skips unnecessary comparisons using bad character and good suffix heuristics

  -> SUFFIX TREE (PREPROCESSING TEXT)
   Preprocesses the entire text instead of the pattern
   Ideal for fixed texts where multiple searches are performed
   Searches take O(M) time, where M is the pattern length
   Used in Trie-based searching techniques

 KEY TAKEAWAYS
  -> Pattern Searching is fundamental in text processing and search engines
  -> KMP, Boyer-Moore, and Z algorithms are preferred for efficient searching
  -> Rabin-Karp is useful when multiple pattern searches are required
  -> Suffix Trees are efficient when the text is fixed, allowing quick searches



RABIN-KARP ALGORITHM & IMPROVED HASHING

 The Rabin-Karp Algorithm is a string matching algorithm that utilizes hashing to
 efficiently search for a pattern in a text. Instead of checking every substring
 individually, it compares hash values, making it significantly faster in average cases

 KEY CONCEPT
 -> Compute the hash of the pattern and the hash of substrings in the text
 -> If the hash values match, perform a character-by-character verification
 -> Uses a rolling hash function to efficiently update the hash value for new substrings
 
 USE CASES
  Text searching in large documents ✅ 
  Plagiarism detection ✅ 
  Searching for multiple patterns efficiently ✅ 
  DNA sequencing and bioinformatics applications ✅ 
  
 NORMAL HASHING (BASIC APPROACH) & ITS LIMITATIONS
  HOW NORMAL HASHING WORKS?
  For a string S = "abcd" of length m, the hash value is computed as:
  H(S) = (d^(m-1) * S[0] + d^(m-2) * S[1] + ... + S[m-1]) mod q
   -> d = Base value (typically 256 for ASCII)
   -> q = Prime number to prevent overflow
   
  EXAMPLE:
  Pattern: "ABC"
   -> ASCII values: A = 65, B = 66, C = 67
   -> Hash calculation with d = 10 and q = 13:
   H("ABC") = (10² × 65 + 10¹ × 66 + 10⁰ × 67) mod 13
   = (6500 + 660 + 67) mod 13
   = 7227 mod 13 = 3
   
   -> Compute hash for every substring in the text
  
  PROBLEM WITH NORMAL HASHING
   -> Computing hash from scratch for EACH WINDOW of the text leads 
      to O(mn) TIME COMPLEXITY (very slow)
   -> SOLUTION? ROLLING HASHING ✅

 ------------------------------------------------

 IMPROVED HASHING: ROLLING HASH TECHNIQUE
   
   WHY IMPROVED HASHING?
    -> Instead of recalculating the hash for each substring from scratch, 
       we derive the NEW HASH from the PREVIOUS HASH in CONSTANT TIME O(1)
    -> Makes RABIN-KARP significantly faster compared to naive methods
    
   ROLLING HASH FORMULA
    Given text T = "ABCD..." and pattern "ABC", update hash as:
    H(Tᵢ₊₁) = (d * (H(Tᵢ) − T[i] * d^(m−1)) + T[i+m]) mod q
    
    EXPLANATION:
     -> Remove contribution of LEFTMOST CHARACTER (T[i] * d^(m-1))
     -> Multiply previous hash by d (shift left)
     -> Add NEW RIGHTMOST CHARACTER (T[i+m])
    
    EXAMPLE:
     Text: "ABCD", window size m = 3
     -> Compute H("ABC") first
     -> Compute H("BCD") using H("ABC") without recomputation
   
   ADVANTAGES OF ROLLING HASH
    Eliminates redundant computations ✅
    Updates hash in O(1) time instead of O(m) ✅
    Suitable for large texts & multiple pattern searches ✅

 ----------------------------------------------

 COLLISIONS & FURTHER IMPROVEMENTS
 
  WHAT IF HASHES MATCH BUT STRINGS ARE DIFFERENT?
   -> HASH COLLISIONS occur when two different substrings have the same hash
   -> Special keyword: "SPURIOUS HITS" ✅
   -> A SPURIOUS HIT is when the hash of a pattern matches the hash of a text window, 
      but the actual strings do not match upon verification

   EXAMPLE:
   Text: "ABABABACD", Pattern: "ABAC"
   -> Hash("ABAC") might match hash("ABAB") → "SPURIOUS HIT"
   -> But after character comparison, the mismatch is detected
   -> Solution? Perform CHARACTER-BY-CHARACTER CHECKING after a hash match ✅
   
  METHODS TO AVOID COLLISIONS
   ✅ LARGER PRIME NUMBERS (q) → Makes hash values more unique
   ✅ DOUBLE HASHING → Use TWO DIFFERENT HASH FUNCTIONS
   ✅ POLYNOMIAL HASHING → Use polynomials to distribute hash values

 RABIN-KARP ALGORITHM STEPS

  1. Compute the hash of the pattern (P)
  2. Compute the hash of the first m characters of the text (T)
  3. Slide the pattern over text:
   -> If H(P) == H(T[i:i+m]), perform CHARACTER-BY-CHARACTER verification 
   -> Else, compute NEXT ROLLING HASH using O(1) update
  4. Repeat until the entire text is scanned

 ---------------------------------------------------------

 KEY TAKEAWAYS
  -> RABIN-KARP optimizes naive search using hashing
  -> ROLLING HASH updates hash in O(1) time
  -> COLLISION HANDLING is necessary to avoid false matches
  -> Special term for false matches: SPURIOUS HITS ✅
  -> Best suited for MULTIPLE PATTERN SEARCHES in large texts
  -> For SINGLE PATTERN SEARCHES, KMP and BOYER-MOORE are often preferred



LONGEST PROPER PREFIX SUFFIX (LPS) ARRAY

 The LPS array for a given string stores the length of the longest proper prefix
 of the string that is also a suffix of the same string, at each index. This array
 is crucial for the KMP (Knuth-Morris-Pratt) algorithm as a pre-processing step

 DEFINITION OF SUFFIX AND PROPER PREFIX

 Consider the string "ABC":
  -> Proper Prefixes: "", "A", "AB" (Note: "ABC" is a prefix but not a *proper* prefix
     as its length is equal to the string's length). A proper prefix has a length strictly less than the string
  -> Suffixes: "", "C", "BC", "ABC".

 EXAMPLE TO UNDERSTAND PROPER PREFIX AND SUFFIX
 For the string "ABCD":
  -> Proper Prefixes: "", "A", "AB", "ABC"
  -> Proper Suffixes: "", "D", "CD", "BCD"

 LPS ARRAY CONSTRUCTION
 The goal is to find the length of the longest proper prefix that is also a suffix at
 every position in the given string.

 RULES FOR LPS ARRAY
  1. The first entry (index 0) of the LPS array is always 0, as a string of length 1
     cannot have a non-empty proper prefix.
  2. For the second entry (index 1), if the first two characters of the string are the
     same, the LPS value is 1; otherwise, it's 0.
  3. For subsequent entries (index i), we consider the substring from the beginning up
     to index i and find the length of the longest proper prefix that is also a suffix of this substring.

 EXAMPLES OF LPS ARRAY

  -> String: "AABA" -> LPS: [0, 1, 0, 1] ('A' at index 0 and 3)
  -> String: "AAAA" -> LPS: [0, 1, 2, 3]
  -> String: "ABCDE" -> LPS: [0, 0, 0, 0, 0]
  -> String: "ABABC" -> LPS: [0, 0, 1, 2, 0] ("AB" is both a proper prefix and suffix of "ABAB")
  -> String: "ABABAB" -> LPS: [0, 0, 1, 2, 3, 4]
  -> String: "aabaacaadaabaaba" -> LPS: [0, 1, 0, 1, 2, 0, 1, 2, 0, 0, 1, 2, 3, 4, 5]
  -> String: "abbabbaba" -> LPS: [0, 0, 1, 2, 0, 1, 2, 3, 4]

 NAIVE APPROACH TO CONSTRUCT LPS ARRAY

  The naive approach involves iterating through all possible proper prefixes of
  each substring and checking if they are also suffixes
 
  Time Complexity: O(n^3), where n is the length of the string. This is because
  for each of the n prefixes, we might compare up to n characters with up to n suffixes
 
  EFFICIENT (LINEAR TIME) APPROACH FOR LPS ARRAY (Used in KMP) ✅
  The efficient approach utilizes already computed LPS values to determine the next LPS value ✅
 
 BASIC IDEAS:

  1. If `str[i]` matches `str[length]` (where `length` is the LPS value of the previous index `i-1`),
     then `LPS[i] = length + 1`, and we increment `length`.

  2. If `str[i]` does not match `str[length]`:
    a. If `length` is 0, then `LPS[i] = 0`, and we move to the next index.
    b. If `length` is greater than 0, we update `length` to `LPS[length - 1]` and repeat the comparison. This step utilizes the information about the longest proper prefix suffix of the prefix of length `length`. We continue this until we find a match or `length` becomes 0.

  DRY RUN EXAMPLE: str = "ABABC"

  | i | str[i] | length | str[length] | Condition             | LPS[i] | length (after) |
  |---|--------|--------|-------------|-----------------------|--------|----------------|
  | 0 | A      | 0      | -           | (Initialization)      | 0      | 0              |
  | 1 | B      | 0      | A           | str[i] != str[length] | 0      | 0              |
  | 2 | A      | 0      | A           | str[i] == str[length] | 1      | 1              |
  | 3 | B      | 1      | B           | str[i] == str[length] | 2      | 2              |
  | 4 | C      | 2      | A           | str[i] != str[length] |        |                |
  |   | C      | 1      | B           | str[i] != str[length] |        |                |
  |   | C      | 0      | A           | length == 0          | 0      | 0              |
  
  Final LPS array: [0, 0, 1, 2, 0]
  
  TIME COMPLEXITY OF EFFICIENT APPROACH: O(n) ✅
  
  Each character `str[i]` is visited at most twice (once when `i` is incremented, and at most
  once more within the `while length != 0` loop, as `length` decreases with each iteration of that loop).
  Therefore, the time complexity is linear with respect to the length of the string.




LEXICOGRAPHIC RANK OF A STRING:

 The LEXICOGRAPHIC RANK of a string is its position in the list of all permutations
 of the string sorted in lexicographic (dictionary) order

 PRE-REQUISITES
  -> Understanding of permutations
  -> Factorial computations (n!)
  -> ASCII-based character comparisons for sorting
  
 STRING: "STRING"
 PERMUTATIONS (sorted): "G...N...R...S...T...", etc.
 RANK: The position at which "STRING" occurs in the sorted permutation list

 EXAMPLE : 
  Suppose the string is "aabc".

  Permutations (in lexicographical order):
  aabc
  aacb
  abac
  abca
  acab
  acba
  baac
  baca
  bcaa
  caab
  caba
  cbaa

 BASIC IDEA
  -> Fix the first character and count how many permutations can be formed
     with smaller characters at that position
  -> Repeat the process for all characters
  
 FORMULA & APPROACH
  For each character in the string:
   -> Count all characters to the right that are smaller than the current character
   -> Multiply the count with factorial of remaining characters
   -> Add all such values for every character
  
  FINAL RANK = SUM + 1
   (Add 1 because ranks start from 1, not 0)

 EXAMPLE:
  STRING: "BAC"
   -> Sorted permutations: "ABC", "ACB", "BAC"
   -> Rank: 3

 STEP-BY-STEP
  S = "BAC"
  1. B → Smaller chars to right = A → 1 × 2! = 2
  2. A → No smaller char to right → 0 × 1! = 0
  3. C → No smaller char to right → 0 × 0! = 0
  Final Rank = 2 + 0 + 0 + 1 = 3 ✅

 TIME & SPACE COMPLEXITY
 +----------------------------------+------------------+
 | METHOD                           | TIME COMPLEXITY  |
 +----------------------------------+------------------+
 | Without Duplicates               | O(N²)             |
 | With Duplicates (using freq map) | O(N × log N)      |
 +----------------------------------+------------------+

 CONSIDERING DUPLICATES
  -> For repeated characters, we divide by factorial of frequencies
     to eliminate identical permutations
  
 EXAMPLE:
  STRING: "AABC"
   -> Total permutations: 4! / (2!) = 12
   -> Use frequency map to adjust for duplicate 'A'

 FORMULA WITH DUPLICATES
   RANK += (count of smaller chars) × (fact of remaining chars) / (product of factorial of frequencies)

 KEY FUNCTIONS REQUIRED
  -> factorial(n) function
  -> freq[] array for duplicate handling
  -> char comparison using ASCII values

 KEY TAKEAWAYS
  -> Lexicographic Rank is useful in combinatorics, encryption, and ordering problems
  -> Requires factorial and frequency-based computation
  -> Efficient handling of duplicates is critical
  -> Optimized solutions use freq[] and BIT/Segment Trees for large input
